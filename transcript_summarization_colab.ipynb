{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéôÔ∏è Transcript Summarization - Testing Notebook\n",
    "\n",
    "This notebook tests the Meeting Summary project's transcription and summarization pipeline.\n",
    "\n",
    "**Models Used (Optimized for Colab GPU quota):**\n",
    "- **Transcription**: `faster-whisper` with `small` model (244MB, high accuracy)\n",
    "- **Summarization**: `sshleifer/distilbart-cnn-12-6` (~1GB, 2x faster than BART-large)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q faster-whisper transformers torch sentencepiece tqdm\n",
    "!pip install -q scipy numpy huggingface-hub\n",
    "\n",
    "# Install FFmpeg for audio processing\n",
    "!apt-get install -qq ffmpeg\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========================================\n",
    "# CONFIGURATION - Modify these as needed\n",
    "# ========================================\n",
    "\n",
    "# Whisper model size: 'tiny', 'base', 'small', 'medium', 'large-v3'\n",
    "# Recommendation: 'small' for best speed/accuracy balance\n",
    "WHISPER_MODEL = \"small\"\n",
    "\n",
    "# Use GPU if available (faster-whisper supports CUDA)\n",
    "USE_GPU = True\n",
    "\n",
    "# Summary word limit\n",
    "SUMMARY_WORD_LIMIT = 500\n",
    "\n",
    "# Model info for reference\n",
    "MODEL_INFO = {\n",
    "    \"tiny\": {\"size\": \"~39 MB\", \"speed\": \"fastest\", \"accuracy\": \"basic\"},\n",
    "    \"base\": {\"size\": \"~74 MB\", \"speed\": \"very fast\", \"accuracy\": \"good\"},\n",
    "    \"small\": {\"size\": \"~244 MB\", \"speed\": \"fast\", \"accuracy\": \"high\"},\n",
    "    \"medium\": {\"size\": \"~769 MB\", \"speed\": \"moderate\", \"accuracy\": \"very high\"},\n",
    "    \"large-v3\": {\"size\": \"~1.5 GB\", \"speed\": \"slow\", \"accuracy\": \"best\"},\n",
    "}\n",
    "\n",
    "print(f\"üìä Selected Whisper Model: {WHISPER_MODEL}\")\n",
    "print(f\"   Size: {MODEL_INFO[WHISPER_MODEL]['size']}\")\n",
    "print(f\"   Speed: {MODEL_INFO[WHISPER_MODEL]['speed']}\")\n",
    "print(f\"   Accuracy: {MODEL_INFO[WHISPER_MODEL]['accuracy']}\")\n",
    "print(f\"\\nüéØ GPU Enabled: {USE_GPU}\")\n",
    "print(f\"üìù Summary Word Limit: {SUMMARY_WORD_LIMIT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé§ Step 3: Fast Transcriber Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "class FastTranscriber:\n",
    "    \"\"\"High-speed transcription using faster-whisper with GPU support.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_size: str = \"small\", use_gpu: bool = True):\n",
    "        self.model_size = model_size\n",
    "        self.use_gpu = use_gpu and torch.cuda.is_available()\n",
    "        self.model = None\n",
    "        self.device = \"cuda\" if self.use_gpu else \"cpu\"\n",
    "        self.compute_type = \"float16\" if self.use_gpu else \"int8\"\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the faster-whisper model.\"\"\"\n",
    "        if self.model is not None:\n",
    "            return\n",
    "        \n",
    "        print(f\"üì• Loading Whisper {self.model_size} model on {self.device.upper()}...\")\n",
    "        \n",
    "        self.model = WhisperModel(\n",
    "            self.model_size,\n",
    "            device=self.device,\n",
    "            compute_type=self.compute_type\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Whisper {self.model_size} model loaded!\")\n",
    "    \n",
    "    def transcribe(self, audio_path: str) -> dict:\n",
    "        \"\"\"Transcribe an audio file.\"\"\"\n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "        \n",
    "        print(f\"üéôÔ∏è Transcribing: {audio_path}\")\n",
    "        \n",
    "        segments, info = self.model.transcribe(\n",
    "            audio_path,\n",
    "            beam_size=1,              # Greedy decoding - faster\n",
    "            vad_filter=True,          # Remove silence\n",
    "            word_timestamps=False,\n",
    "            condition_on_previous_text=False\n",
    "        )\n",
    "        \n",
    "        segment_list = []\n",
    "        full_text = []\n",
    "        \n",
    "        for seg in segments:\n",
    "            segment_list.append({\n",
    "                \"start\": seg.start,\n",
    "                \"end\": seg.end,\n",
    "                \"text\": seg.text.strip()\n",
    "            })\n",
    "            full_text.append(seg.text.strip())\n",
    "        \n",
    "        transcript = \" \".join(full_text)\n",
    "        \n",
    "        print(f\"‚úÖ Transcription complete!\")\n",
    "        print(f\"   Language: {info.language}\")\n",
    "        print(f\"   Length: {len(transcript):,} chars | {len(transcript.split()):,} words\")\n",
    "        \n",
    "        return {\n",
    "            \"text\": transcript,\n",
    "            \"segments\": segment_list,\n",
    "            \"language\": info.language,\n",
    "            \"word_count\": len(transcript.split())\n",
    "        }\n",
    "    \n",
    "    def format_with_timestamps(self, result: dict) -> str:\n",
    "        \"\"\"Format transcript with timestamps.\"\"\"\n",
    "        lines = []\n",
    "        for seg in result.get(\"segments\", []):\n",
    "            start = self._format_time(seg[\"start\"])\n",
    "            end = self._format_time(seg[\"end\"])\n",
    "            lines.append(f\"[{start} ‚Üí {end}] {seg['text']}\")\n",
    "        return \"\\n\".join(lines)\n",
    "    \n",
    "    def _format_time(self, seconds: float) -> str:\n",
    "        mins = int(seconds // 60)\n",
    "        secs = int(seconds % 60)\n",
    "        return f\"{mins:02d}:{secs:02d}\"\n",
    "\n",
    "print(\"‚úÖ FastTranscriber class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Step 4: Summarizer Class (DistilBART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from datetime import datetime\n",
    "\n",
    "class Summarizer:\n",
    "    \"\"\"Summarizes transcripts using DistilBART (2x faster than BART-large).\"\"\"\n",
    "    \n",
    "    MODEL_NAME = \"sshleifer/distilbart-cnn-12-6\"\n",
    "    \n",
    "    def __init__(self, use_gpu: bool = True):\n",
    "        self.device = \"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the DistilBART model.\"\"\"\n",
    "        if self.model is not None:\n",
    "            return\n",
    "        \n",
    "        print(f\"üì• Loading DistilBART model on {self.device.upper()}...\")\n",
    "        \n",
    "        self.tokenizer = BartTokenizer.from_pretrained(self.MODEL_NAME)\n",
    "        self.model = BartForConditionalGeneration.from_pretrained(self.MODEL_NAME)\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        print(\"‚úÖ DistilBART model loaded!\")\n",
    "    \n",
    "    def summarize(self, transcript: str, word_limit: int = 500) -> str:\n",
    "        \"\"\"Generate a structured summary.\"\"\"\n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "        \n",
    "        print(f\"üìù Generating summary (~{word_limit} words)...\")\n",
    "        \n",
    "        if not transcript.strip():\n",
    "            return \"No content to summarize.\"\n",
    "        \n",
    "        # Chunk the transcript for processing\n",
    "        chunks = self._chunk_text(transcript, max_length=2000)\n",
    "        \n",
    "        summaries = []\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            print(f\"   Processing chunk {i+1}/{len(chunks)}...\")\n",
    "            summary = self._summarize_chunk(chunk)\n",
    "            if summary:\n",
    "                summaries.append(summary)\n",
    "        \n",
    "        detailed_summary = \"\\n\\n\".join(summaries)\n",
    "        \n",
    "        # Trim to word limit\n",
    "        words = detailed_summary.split()\n",
    "        if len(words) > word_limit * 1.2:\n",
    "            detailed_summary = \" \".join(words[:word_limit]) + \"...\"\n",
    "        \n",
    "        # Generate executive summary\n",
    "        exec_summary = self._summarize_chunk(detailed_summary[:2000]) if len(detailed_summary) > 500 else detailed_summary\n",
    "        \n",
    "        # Extract key points\n",
    "        key_points = self._extract_key_points(summaries)\n",
    "        \n",
    "        # Format output\n",
    "        output = f\"\"\"# Meeting Summary\n",
    "**Generated:** {datetime.now().strftime(\"%Y-%m-%d %H:%M\")}\n",
    "**Transcript Length:** {len(transcript):,} characters | {len(transcript.split()):,} words\n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "{exec_summary}\n",
    "\n",
    "---\n",
    "\n",
    "## Detailed Summary\n",
    "{detailed_summary}\n",
    "\n",
    "---\n",
    "\n",
    "## Key Points\n",
    "{key_points}\n",
    "\n",
    "---\n",
    "\n",
    "*Generated by Meeting Summary App using DistilBART*\n",
    "\"\"\"\n",
    "        \n",
    "        print(\"‚úÖ Summary generation complete!\")\n",
    "        return output\n",
    "    \n",
    "    def _summarize_chunk(self, text: str) -> str:\n",
    "        \"\"\"Summarize a single chunk.\"\"\"\n",
    "        if not text.strip():\n",
    "            return \"\"\n",
    "        \n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=1024,\n",
    "            truncation=True\n",
    "        ).to(self.device)\n",
    "        \n",
    "        summary_ids = self.model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_length=200,\n",
    "            min_length=50,\n",
    "            length_penalty=1.5,\n",
    "            num_beams=2,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "        \n",
    "        return self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    def _chunk_text(self, text: str, max_length: int) -> list:\n",
    "        \"\"\"Split text into chunks.\"\"\"\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        current = []\n",
    "        length = 0\n",
    "        \n",
    "        for word in words:\n",
    "            if length + len(word) > max_length and current:\n",
    "                chunks.append(\" \".join(current))\n",
    "                current = [word]\n",
    "                length = len(word)\n",
    "            else:\n",
    "                current.append(word)\n",
    "                length += len(word) + 1\n",
    "        \n",
    "        if current:\n",
    "            chunks.append(\" \".join(current))\n",
    "        \n",
    "        return chunks if chunks else [text]\n",
    "    \n",
    "    def _extract_key_points(self, summaries: list) -> str:\n",
    "        \"\"\"Extract key points as bullet points.\"\"\"\n",
    "        points = []\n",
    "        for summary in summaries:\n",
    "            sentences = summary.split('.')\n",
    "            if sentences and len(sentences[0].strip()) > 20:\n",
    "                points.append(f\"‚Ä¢ {sentences[0].strip()}.\")\n",
    "        \n",
    "        return \"\\n\".join(points[:8]) if points else \"‚Ä¢ Key points from the meeting above.\"\n",
    "\n",
    "print(\"‚úÖ Summarizer class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì§ Step 5: Upload Your Audio/Video File\n",
    "\n",
    "Upload an audio file (MP3, WAV) or video file (MP4, etc.) to test the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"üì§ Please upload an audio/video file...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the uploaded file path\n",
    "uploaded_file = list(uploaded.keys())[0]\n",
    "print(f\"\\n‚úÖ Uploaded: {uploaded_file}\")\n",
    "print(f\"   Size: {os.path.getsize(uploaded_file) / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé¨ Step 6: Extract Audio (if video file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def extract_audio(input_file: str) -> str:\n",
    "    \"\"\"Extract audio from video file using FFmpeg.\"\"\"\n",
    "    # Check if already audio file\n",
    "    audio_extensions = ['.mp3', '.wav', '.m4a', '.flac', '.ogg', '.aac']\n",
    "    if any(input_file.lower().endswith(ext) for ext in audio_extensions):\n",
    "        print(f\"‚úÖ File is already audio: {input_file}\")\n",
    "        return input_file\n",
    "    \n",
    "    # Extract audio from video\n",
    "    output_file = \"extracted_audio.wav\"\n",
    "    \n",
    "    print(f\"üé¨ Extracting audio from video...\")\n",
    "    \n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-y\", \"-i\", input_file,\n",
    "        \"-vn\",                    # No video\n",
    "        \"-acodec\", \"pcm_s16le\",   # WAV format\n",
    "        \"-ar\", \"16000\",           # 16kHz (optimal for Whisper)\n",
    "        \"-ac\", \"1\",               # Mono\n",
    "        output_file\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úÖ Audio extracted: {output_file}\")\n",
    "        print(f\"   Size: {os.path.getsize(output_file) / (1024*1024):.2f} MB\")\n",
    "        return output_file\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {result.stderr}\")\n",
    "        return input_file\n",
    "\n",
    "# Extract audio\n",
    "audio_file = extract_audio(uploaded_file)\n",
    "print(f\"\\nüéµ Audio file ready: {audio_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 7: Run Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Initialize transcriber\n",
    "transcriber = FastTranscriber(model_size=WHISPER_MODEL, use_gpu=USE_GPU)\n",
    "\n",
    "# Transcribe\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéôÔ∏è STARTING TRANSCRIPTION\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "result = transcriber.transcribe(audio_file)\n",
    "transcription_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Transcription Time: {transcription_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÑ Step 8: View Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display transcript with timestamps\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìú TRANSCRIPT WITH TIMESTAMPS\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "formatted_transcript = transcriber.format_with_timestamps(result)\n",
    "print(formatted_transcript[:3000])  # Show first 3000 chars\n",
    "\n",
    "if len(formatted_transcript) > 3000:\n",
    "    print(f\"\\n... [Truncated - Full transcript is {len(formatted_transcript):,} characters]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Step 9: Generate Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize summarizer\n",
    "summarizer = Summarizer(use_gpu=USE_GPU)\n",
    "\n",
    "# Generate summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìù GENERATING SUMMARY\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "summary = summarizer.summarize(result[\"text\"], word_limit=SUMMARY_WORD_LIMIT)\n",
    "summary_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Summary Generation Time: {summary_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 10: View Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìä MEETING SUMMARY\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "# Display as formatted markdown\n",
    "display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 11: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Save transcript\n",
    "transcript_filename = \"transcript.txt\"\n",
    "with open(transcript_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(formatted_transcript)\n",
    "\n",
    "# Save summary\n",
    "summary_filename = \"summary.md\"\n",
    "with open(summary_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"üì• Downloading files...\")\n",
    "files.download(transcript_filename)\n",
    "files.download(summary_filename)\n",
    "\n",
    "print(\"\\n‚úÖ Done! Files downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 12: Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìà PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "üîß Configuration:\n",
    "   ‚Ä¢ Whisper Model: {WHISPER_MODEL} ({MODEL_INFO[WHISPER_MODEL]['size']})\n",
    "   ‚Ä¢ Device: {'GPU (CUDA)' if torch.cuda.is_available() else 'CPU'}\n",
    "   ‚Ä¢ Summary Word Limit: {SUMMARY_WORD_LIMIT}\n",
    "\n",
    "üìä Results:\n",
    "   ‚Ä¢ Transcript Words: {result['word_count']:,}\n",
    "   ‚Ä¢ Transcript Characters: {len(result['text']):,}\n",
    "   ‚Ä¢ Detected Language: {result['language']}\n",
    "\n",
    "‚è±Ô∏è Timing:\n",
    "   ‚Ä¢ Transcription: {transcription_time:.2f}s\n",
    "   ‚Ä¢ Summarization: {summary_time:.2f}s\n",
    "   ‚Ä¢ Total: {transcription_time + summary_time:.2f}s\n",
    "\n",
    "üíæ Files Saved:\n",
    "   ‚Ä¢ transcript.txt\n",
    "   ‚Ä¢ summary.md\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ All tests completed successfully!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Alternative: Test with Sample Text\n",
    "\n",
    "If you don't have an audio file, you can test just the summarization with sample text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample meeting transcript for testing summarization only\n",
    "SAMPLE_TRANSCRIPT = \"\"\"\n",
    "Welcome everyone to today's product planning meeting. We have several important topics to cover.\n",
    "\n",
    "First, let's discuss the Q1 roadmap. Our main priority is launching the mobile app by end of February.\n",
    "The development team has been making good progress on the core features. Sarah mentioned that the \n",
    "authentication module is complete and we're now working on the dashboard.\n",
    "\n",
    "John from the design team shared the latest mockups. The stakeholders approved the new color scheme\n",
    "and we'll be implementing those changes next week. We need to finalize the icon set by Friday.\n",
    "\n",
    "Regarding the backend, Mike reported that the API is 80% complete. We still need to implement the\n",
    "notification system and the analytics tracking. These should be done by next Wednesday.\n",
    "\n",
    "For marketing, Lisa prepared a launch strategy. We'll start a teaser campaign on social media two\n",
    "weeks before launch. The press release will go out to tech publications on launch day.\n",
    "\n",
    "Budget update: We're currently under budget by 15%, which gives us room for additional testing\n",
    "resources if needed. Alice suggested hiring a QA contractor for the final testing phase.\n",
    "\n",
    "Action items: Sarah will complete the dashboard by Friday. John will finalize icons. Mike will\n",
    "finish the notification API. Lisa will prepare social media content. Alice will interview QA candidates.\n",
    "\n",
    "Our next meeting is scheduled for next Monday at 10 AM. Thank you everyone for your participation.\n",
    "\"\"\"\n",
    "\n",
    "# Test summarization with sample text\n",
    "print(\"\\nüß™ Testing summarization with sample transcript...\\n\")\n",
    "\n",
    "test_summarizer = Summarizer(use_gpu=USE_GPU)\n",
    "test_summary = test_summarizer.summarize(SAMPLE_TRANSCRIPT, word_limit=200)\n",
    "\n",
    "display(Markdown(test_summary))"
   ]
  }
 ]
}
